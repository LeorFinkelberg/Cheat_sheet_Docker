\documentclass[%
	11pt,
	a4paper,
	utf8,
	%twocolumn
		]{article}	

\usepackage{style_packages/podvoyskiy_article_extended}


\begin{document}
\title{Практика использования и \\наиболее полезные конструкции \texttt{Docker}}

\author{\itshape Подвойский А.О.}

\date{}
\maketitle

\thispagestyle{fancy}

\tableofcontents

\section{Общие сведения о системе Docker}

\subsection{Термины и определения}

\paragraph{Контейнер} -- это НЕ виртуальная машина, а \emph{приложение  и его зависимости}, упакованные в стандартизированное, изолированное, легковесное окружение. Контейнеры используют виртуализацию на уровне ядра операционной системы и не содержат своей собственной операционной системы, поэтому они такие легкие.

\paragraph{Образ} -- неизменяемая сущность, снимок контейнера. Образ состоит из слоев.

\paragraph{{localhost}} (так называемый, <<локальный хост>>, по смыслу <<этот компьютер>>) -- стандартное, официально зарезервированное доменное имя для \emph{частых} (или что то же самое \emph{локальных}) IP-адресов\footnote{Уникальный сетевой адрес узла в компьютерной сети, построенной на базе стека протоколов TCP/IP} \emph{петлевого интерфейса}\footnote{Обычно используется термин \emph{loopback}, который описывает методы или процедуры маршрутизации электронных сигналов, цифровых потоков данных, или других движущихся сущностей от их источника и обратно к тому же источнику без специальной обработки или модификации} (диапазон \texttt{127.0.0.1} -- \texttt{127.255.255.255}). Использование IP-адреса \texttt{127.0.0.1} позволяет устанавливать соединение и передавать информацию для программ-серверов, работающих на том же компьютере, что и программа-клиент. Примером может быть запущенный на компьютере веб-сервер приложений, обращение к которому выполняется с этого же компьютера для веб-разработки на данном компьютере без необходимости выкладывать веб-программу в сеть Интернет, пока ее разработка не закончена. Традиционно IP-адресу \texttt{127.0.0.1} однозначно сопоставляется имя хоста \texttt{localhost}.

\paragraph{{порт}} целое неотрицательное число, записываемое в заголовках \emph{протоколов транспортного уровня} модели OSI (TCP, UDP, SCTP, DCCP). Используется для определения процесса-получателя пакета в пределах одного хоста (локального компьютера).

\subsection{Высокоуровневая концепция}

На одной физической машине  может находится несколько виртуальных машин (например, ОС Windows, ОС Linux и OC MacOS X), которые не будут знать ничего друг о друге (\pic{fig:containervsvm}). На этих виртуальных машинах, разумеется, могут быть установлены различные приложения, специфичные для конкретной операционной системы и т.д. Но каждая такая виртуальная машина не знает, что она виртуальная.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.45]{figures/container_vs_VM.png}
	\caption{ Сравнение архитектуры docker-контейнеров и виртуальных машин }\label{fig:containervsvm}
\end{figure}

В случае с Docker внутри одного контейнера может существовать несколько приложений, которые взаимодействуют с одной операционной системой (ОС физической машины).

Внутри контейнера может быть:
\begin{itemize}
	\item Приложение (Java/Ruby/Go etc.),
	
	\item Библиотеки (libxml, wkhtmltopdf etc.),
	
	\item Сервисы (PostgeSQL, Redis etc.),
	
	\item Утилиты (sbt, ant, gems, eggs etc.),
	
	\item Фреймворки (jre, ruby etc.)
\end{itemize}

В разных контейнерах могут стоять различные версии перечисленных объектов.

Docker состоит из Daemon, Client и Registry. \emph{Docker-демон} запускается на машине (локальная машина, сервер или что-то еще), на которой планируется запускать контейнеры. Также предоставляет API и управляет docker-объектами (Dockerfile, ...).

\emph{Docker-клиент} принимает команды пользователя и общается по API с docker-демоном.

В сущности Docker-pipeline представляет собой следующую цепочку:
\begin{itemize}
	\item На базе файла \texttt{Dockerfile} собирается \emph{образ} с помощью \texttt{docker build} (на локальной машине),
	
	\item На базе образа запускается \emph{контейнер} с помощью \texttt{docker run}.
\end{itemize}

Пример Dockerfile
\begin{lstlisting}[
style = bash,
numbers = none	
]
FROM python:3.7.2-alpine3.8
LABEL maintainer="jeffmshale@gmail.com"
ENV ADMIN="jeff"

RUN apk update && apk upgrade && apk add bash # форма оболочки

COPY . ./app

ADD https://raw.githubusercontent.com/discdiver/pachy-vid/master/sample_vids/vid1.mp4 \
/my_app_directory

RUN ["mkdir", "/a_directory"] # JSON-форма

CMD ["python", "./my_script.py"]
\end{lstlisting}

\texttt{FROM}: в роли базового образа выступает официальный Python-образ с тегом 3.7.2-alpine3.8. 

\texttt{LABEL}: добавляет метаданные к образу, предоставляет контактную информацию. Она не замедляет процесс запуска и не занимает много места, наоборот, обеспечивает образ полезной информацией.

\texttt{ENV}: создает переменную окружения, которая становится доступной во время запуска контейнера. 

\texttt{RUN}: запускает заданную инструкцию внутри контейнера. Docker фиксирует состояние образа после каждой инструкции \texttt{RUN}. Чаще всего используется для установки нужных пакетов внутрь контейнера. \texttt{RUN} и ее родственные конструкции (\texttt{CMD}, \texttt{ENTRYPOINT}) -- могут быть как в форме оболочки, так и в JSON-форме. Во втором случае используют JSON-синтаксис 
\begin{lstlisting}[
style = bash,
numbers = none	
]
RUN ["my_executable", "my_first_param1", "my_second_param2"]|
\end{lstlisting}

А в примере выше использовалась форма оболочки 
\begin{lstlisting}[
style = bash,
numbers = none	
]
RUN apk update && apk upgrade && apk add bash
\end{lstlisting}

\texttt{COPY}: инструкция \verb|COPY . ./app| говорит Docker'у, что нужно скопировать файлы и папки из вашей локальной сборки в рабочую директорию образа. \texttt{COPY} создаст все нужные папки, если они осутствуют.

\texttt{ADD}: делает то же самое, что и \texttt{COPY}, но с двумя отличиями. \texttt{ADD} может загружать файл по URL, а также извлекать локальные tar-файлы.

В примере выше \texttt{ADD} копировала файлы по URL внутрь директории контейнера. Но официальной документации не рекомендуется использовать \texttt{ADD}. Однако, в общем случае лучше воспользоваться более простой инструкцией \texttt{COPY} для копирования файлов и каталогов в локальном контексте создания или инструкцией \texttt{RUN} с запуском \texttt{curl} или \texttt{wget} для загрузки удаленных ресурсов.

\texttt{CMD}: инструкция для запуска чего-либо во время запуска самого контейнера, то есть инструкция запускается во время инициализации контейнера. По ходу сборки она не фиксирует никакого результата. В примере выше во время сборки запускался сценарий \verb|my_script.py|. Если была определена инструкция \texttt{ENTRYPOINT}, то заданная здесь инструкция будет интерпретироваться как аргумент для \texttt{ENTRYPOINT}. Инструкция \texttt{CMD} замещается любыми аргументами, указанными в команде \texttt{docker run} после имени образа. В действительности выполняется только самая последняя инструкция \texttt{CMD}, а все предыдущие инструкции \texttt{CMD} будут отменены.

\texttt{WORKDIR}: меняет текущую рабочую директорию для инструций: \texttt{COPY}, \texttt{ADD}, \texttt{RUN} и \texttt{ENTRYPOINT}. Предпочтительно задавать абсолютный путь. \texttt{WORKDIR} автоматически создает директорию, если ее еще нет. Можно использовать несколько \texttt{WORKDIR}-инструкций.

\texttt{ARG}: определяет переменную для передачи из командной строки в образ. Для \texttt{ARG} можно указать значение по умолчанию \texttt{ARG my\_var=my\_default\_value}. Например
\begin{lstlisting}[
style = bash,
numbers = none	
]
...
ARG my_var=my_default_value

ENTRYPOINT ["python", "./app/my_script.py", "my_var"] # будет прочитано значение my_var
...
\end{lstlisting}

В отличие от \texttt{ENV}-переменных \texttt{ARG}-переменные не доступны для запущенных контейнеров. Другими словами, нельзя напрямую установить значение переменных \texttt{ENV} при запуске сборки образа с помощью \texttt{docker build}. Но можно использовать \texttt{ARG} для передачи значений в инструкции \texttt{ENV}.

Например \url{https://vsupalov.com/articles/}
\begin{lstlisting}[
title = {\sffamily Dockerfile},
style = bash,
numbers = none	
]
...
# переменная buildtime_variable со значением по умолчанию
ARG buildtime_variable=default_value # существует только для передачи значения в переменную окружения

ENV env_var_name=$buildtime_variable
...
\end{lstlisting}

Теперь при запуске сборки образа можно переопределять значение переменной \verb|buildtime_variable| <<на лету>>
\begin{lstlisting}[
style = bash,
numbers = none	
]
docker build --build-arg buildtime_variable=a_value ...
\end{lstlisting}

То есть можно изменять значение переменной \verb|buildtime_variable| без необходимости вносить изменения в \texttt{Dockerfile}.

\texttt{ENTRYPOINT}: также позволяет задавать дефолтные команды и аргументы во время запуска контейнера. Аргументы командной строки, передаваемые \texttt{docker run my\_image\_name}, добавляются к аргументам инструкции \texttt{ENTRYPOINT}. Например,
\begin{lstlisting}[
style = bash,
numbers = none	
]
docker run my_image_name bash
\end{lstlisting}
добавляет аргумент \texttt{bash} в конец, ко всем другим аргументам \texttt{ENTRYPOINT}.

\texttt{Dockerfile} должен обязательно содержать либо \texttt{CMD}-инструкцию, либо \texttt{ENTRYPOINT}-инструкцию. В официальной документации есть несколько советов, которые помогут сделать выбор между \texttt{CMD} и \texttt{ENTRYPOINT}
\begin{itemize}
	\item Если вам нужно запускать одну и ту же команду несколько раз, выбирайте \texttt{ENTRYPOINT},
	
	\item Используйте \texttt{ENTRYPOINT}, когда ваш контейнер выступает в роли исполняющей программы,
	
	\item При наличии дополнительных дефолтных аргументов, которые могут быть изменены через командную строку, лучше подойдет \texttt{CMD}.
\end{itemize}

\texttt{EXPOSE}: показывает какой порт пробрасывать из контейнера. Используйте команду \texttt{docker run} с флагом \verb|-p| для пробрасывания и сопоставления нескольких портов во время запуска. Флаг в верхнем регистре \verb|-P| будет пробрасывать все открытые порты.

\texttt{VOLUME}: определяет, где контейнер будет хранить постоянные данные и получать к ним доступ.

\subsection{Установка}

Установить \texttt{Docker} можно с помощью менеджера пакетов \texttt{conda}

\begin{lstlisting}[
style = ironpython,
numbers = none
]
conda install -c conda-forge docker-py
\end{lstlisting}

На текущий момент без серьезных проблем \texttt{Docker} работает только на 64-битовом \texttt{Linux}.

Для нормальной работы на \texttt{MacOS X} или \texttt{Windows} потребуется дополнительно установить какую-либо виртуальную машину в полной комплектации или пакет \texttt{Docker Toolbox}:

\begin{itemize}
	\item для \texttt{MacOS X}: \url{https://docs.docker.com/toolbox/toolbox_install_mac/},
	
	\item для \texttt{Windows}\footnote{Поддерживается даже \texttt{Windows 7}}: \url{https://docs.docker.com/toolbox/toolbox_install_windows/}; после установки \texttt{Docker Toolbox} останется только запустить \texttt{Docker Quick Start Terminal}.
\end{itemize}

То есть на операционных системах Windows и MacOS X для того, чтобы можно было работать с Docker, требуется поднять виртуальную машину Linux VM, внутри которой будут существовать docker-демон и контейнеры.

\subsection{Анализ manifest-файлов Docker}

Чтобы извлечь данные с удаленного репозитория нужно воспользоваться конструкцией
\begin{lstlisting}[
style = bash,
numbers = none
]
docker pull leorfinkelberg/app_name:tag_name
\end{lstlisting}
или что то же самое (по умолчанию, если хост не указан, используется DockerHub)
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker pull registry.hub.docker.com/leorfinkelberg/app_name:tag_name
\end{lstlisting}

Пытаемся скачать manifest-файл
\begin{lstlisting}[
style = bash,
numbers = none
]
$ curl -D - -s https://registry.hub.docker.com/v2/leorfinkelberg/manifests/latest
# вернет
HTTP/1.1 401 Unauthorized
Content-Type: application/json
Docker-Distribution-Api-Version: registry/2.0
Www-Authenticate: Bearer realm="https://auth.docker.io/token",service="registry.docker.io",scope="repository:leorfinkelberg/myapp:pull"
Date: Thu, 04 Jun 2020 17:57:01 GMT
Content-Length: 163
Strict-Transport-Security: max-age=31536000

{"errors":[{"code":"UNAUTHORIZED","message":"authentication required","detail":[{"Type":"repository","Class":"","Name":"leorfinkelberg/myapp","Action":"pull"}]}]}
\end{lstlisting}

Здесь флаг \verb|-D| сохраняет заголовки, возвращенные сервером, \verb|-s| заставляет выводить минимум информации.

Возникли сложности с авторизацией. Смотрим на строку \texttt{Www-Authenticate} и на основании информации, приведенной в этой строке, строим запрос
\begin{lstlisting}[
style = bash,
numbers = none
]
$ curl -D - -s 'https://auth.docker.io/token?service=registry.docker.io&scope=repository:leorfinkelberg/myapp:pull'
# вернет
HTTP/1.1 200 OK
Content-Type: application/json
Date: Thu, 04 Jun 2020 13:46:22 GMT
Transfer-Encoding: chunked
Strict-Transport-Security: max-age=31536000

{"token":"eyJhbGciOiJSUzI1NiIsInR5cCI6...}
\end{lstlisting}

Параметр \verb|scope| описывает запрашиваемые права. Затем создаем переменную окружения \texttt{REGISTRY\_TOKEN}
\begin{lstlisting}[
style = bash,
numbers = none
]
export REGISTRY_TOKEN="eyJhbGciOiJSUzI1NiIsInR5..."
\end{lstlisting}

А затем конструируем такой запрос и получаем manifest-файл в формате json
\begin{lstlisting}[
style = bash,
numbers = none
]
$ curl -D - -s -H "Authorization: Bearer $REGISTRY_TOKEN" https://registry.hub.docker.com/v2/leorfinkelberg/myapp/manifests/latest
# вернет
HTTP/1.1 200 OK
Content-Length: 5778
Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws
Docker-Content-Digest: sha256:cb0c53e4c8471a2deb8d22df00646ee2abe81cb11818ed12d0fe4e697ccec93f
Docker-Distribution-Api-Version: registry/2.0
Etag: "sha256:cb0c53e4c8471a2deb8d22df00646ee2abe81cb11818ed12d0fe4e697ccec93f"
Date: Thu, 04 Jun 2020 18:11:59 GMT
Strict-Transport-Security: max-age=31536000

{
    "schemaVersion": 1,
    "name": "leorfinkelberg/myapp",
    "tag": "latest",
    "architecture": "amd64",
    "fsLayers": [
        {
            "blobSum": "sha256:bd1a014b71c4b5b06a7f57486a8be2d690fc6034ede049ab63e9e827c9814e5a"
        },
...
    "signatures": [
        {
            "header": {
               "jwk": {
                   "crv": "P-256",
                   "kid": "PDNB:TMYN:5AZL:Y3UQ:6ACR:VJER:ON6K:H5XV:AIUX:7ZBZ:2PUD:GUI4",
                   "kty": "EC",
                   "x": "o_2HgAeBYjFsEhtDbFsB0afzrwkODIgIsDg7Tslk33o",
                   "y": "04Wp7S22uBJYbca2CABSBIl8ZkJUksit8dLQDvshhro"
               },
               "alg": "ES256
            },
            "signature": "eWlDslYAVkLGltlSfB9-Pboa3aWIuKEkaMomNx07xH...",
            "protected": "eyJmb3JtYXRMZW5ndGgiOjUxMzEsImZvcm1hdFRhaWwiOi..."
        }
    ]
}
\end{lstlisting}

Сохраняем manifest-файл
\begin{lstlisting}[
style = bash,
numbers = none
]
curl -o manifest.json -s -H "Authorization: Bearer $REGISTRY_TOKEN" https://registry.hub.docker.com/v2/leorfinkelberg/myapp/manifests/latest
\end{lstlisting}

Контрольные суммы слоев образа можно посмотреть так
\begin{lstlisting}[
style = bash,
numbers = none
]
$ $ docker inspect --format {{.RootFS.Layers}} leorfinkelberg/myapp
\end{lstlisting}


\subsection{Контейнеры}

\emph{Контейнеры} представляют собой средства инкапсуляции приложения вместе со всеми его зависимостями.

Поскольку \texttt{Docker} сам по себе не обеспечивает реализацию любого типа виртуализации, контейнеры всегда должны соответствовать ядру хоста -- контейнер на \texttt{Windows Server} может работать только на хосте под управлением операционной системы \texttt{Windows Server}, а 64-битный \texttt{Linux}-контейнер работает только на хосте с установленной 64-битной версией операционной системы \texttt{Linux} \cite{mouat:docker-2017}.

\subsection{Создание образов из Dockerfile}

\texttt{Dockerfile} -- это обычный текстовый файл, содержащий набор операций, которые могут быть использованы для создания Docker-образа.

Пример. Для начала создадим новый каталог и собственно Dockerfile

\begin{lstlisting}[
numbers = none
]
$ mkdir cowsay
$ cd cowsay
$ touch Dockerfile
\end{lstlisting}

Затем в созданный \texttt{Dockerfile} добавим следующее 
\begin{lstlisting}[
title = {\sffamily Dockerfile},
numbers = none
]
FROM debian:wheezy
MAINTAINER John Smith <john@smith.com>
RUN apt-get update && apt-get install -y cowsay fortune
COPY entrypoint.sh /
ENTRYPOINT ["/entrypoint.sh"]
\end{lstlisting}

Инструкция \texttt{FROM} определяет базовый образ ОС (это в данном случае \texttt{debian} с уточненной версией <<wheezy>>). Инструкция \texttt{FROM} является строго обязательной для всех файлов Dockerfile как самая первая незакомментированная инструкция.

Инструкция \texttt{MAINTAINER} просто определяет информацию, позволяющую связаться с автором образа.

Инструкция \texttt{COPY} копирует файл из файловой системы хоста в файловую систему образа, где первый аргумент определяет файл хост, а второй -- целевой путь.

Инструкция \texttt{RUN} определяет команды, выполняемые в командной оболочке внутри данного образа.

Комментарии к скрипту \texttt{entrypoint.sh}. Файл \texttt{entrypoint.sh} должен лежать в той же директории, что и файл \texttt{Dockerfile} и иметь содержание на подобие следующего
\begin{lstlisting}[
title = {\sffamily entrypoint.sh},
numbers = none
]
if [ $# -eq 0 ]; then
    /usr/games/fortune | /usr/games/cowsay
else
    /usr/games/cowsay "$@"
fi
\end{lstlisting}

Здесь конструкция \texttt{[...]} -- это форма\footnote{Есть еще вариант \texttt{test выражение}, но форма \texttt{[ выражение ]} более популярна} команды \texttt{test} для проверки различных условий. Последовательность символов \texttt{\$\#} -- встроенная переменная, обозначающая количество аргументов в командной строке. Последовательность символов \texttt{\$@} -- это все аргументы командной строки, а \texttt{"\$@"} -- все аргументы командной строки, заключенные по отдельности в кавычки \cite[\strbook{44}]{robbins:bash-2017}.

После сохранения необходимо сделать этот файл исполняемым при помощи команды\\ \texttt{chmod +x entrypoint.sh}.

Теперь можно создать образ на основе файла \texttt{Dockerfile}
\begin{lstlisting}[
numbers = none
]
docker build -t test/cowsay-dockerfile .
\end{lstlisting}

Здесь \texttt{test} -- имя репозитория, а \texttt{cowsay-dockerfile} -- имя образа.

После этого можно запускать контейнер, который строится на основе образа \verb|test/cowsay-dockerfile|
\begin{lstlisting}[
numbers = none
]
docker run test/cowsay-dockerfile Moo
\end{lstlisting}

\subsection{Пример файла docker-compose.yml}

Рассмотрим в качестве примера файл \texttt{docker-compose.yml} для автоматизации процесса настройки и запуска контейнера
\begin{lstlisting}[
style = bash,
title = {\sffamily docker-compose.yml},
numbers = none
]
registry:
    restart: always
    image: registry:2
    ports:
        - 443:5000
    environment:
        REGISTRY_HTTP_ADDR: 0.0.0.0:5000
        REGISTRY_HTTP_HOST: https://registry.kis.im
        REGISTRY_HTTP_TLS_LETSENCRYPT_CACHEFILE: /tmp/le.cache
        REGISTRY_HTTP_TLS_LETSENCRYPT_EMAIL: ov@rebrain.com
        REGISTRY_HTTP_TLS_LETSENCRYPT_HOSTS: [registry.kis.im]
    volumes:
        - /path/data:/var/lib/registry
        - /path/cers:/certs
\end{lstlisting}

Описание. Создаем сервис \texttt{registry} с политикой постоянной перезагрузки. Образ используется официальный \texttt{registry-2}. Пробрасываем 443 порт на 5000 внутрь контейнера.

Для запуска контейнера достаточно набрать
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker-compose up -d
\end{lstlisting}

\subsection{Порядок работы с docker-compose}

Docker-compose придумали для того, чтобы создавать себе на локальном компьютере (или окружении для \emph{тестов}) \emph{эмуляцию} продакшн среды. В действительности речь идет о распределенном приложении, которое будет работать на нескольких машинах, но для того чтобы посмотреть связку этих раздельных блоков на локальной машине (например, для проведения интеграционных тестов) можно использовать docker-compose.

Обычный порядок работы начинается с выполнения команды для запуска приложения
\begin{lstlisting}[
style = bash,
numbers = none
]
docker-compose up -d
\end{lstlisting}

Команды \texttt{docker-compose logs} и \texttt{docker-compose ps} могут использоваться для проверки состояния приложения и как вспомогательное средство при отладке.

После внесения изменений в исходный код нужно выполнить
\begin{lstlisting}[
style = bash,
numbers = none
]
docker-compose build
\end{lstlisting}
а затем 
\begin{lstlisting}[
style = bash,
numbers = none
]
docker-compose up -d
\end{lstlisting}

При этом будет создан новый образ и заменен работающий контейнер.

\remark{%
Compose сохраняет все ранее существовавшие тома из старых контейнеров, таким образом, базы данных и кэши остаются неизменными при переходе к новым версиям контейнеров (это может привести к беспорядку, поэтому будьте осторожны при замене контейнеров)}

Если создание нового образа не требуется, но внесены изменения в docker-compose.yml, то выполните команду \texttt{docker-compose up -d}, чтобы заменить контейнер на точно такой же, но с новыми настройками.

После завершения сеанса работы с приложением выполните команду \texttt{docker-compose stop} для его остановки. Тот же самый комплект контейнеров будет повторно запущен при выполнении команды \texttt{docker-compose start} или \texttt{docker-compose up -d}, если не был изменен исходный код.

Для окончательного удаления набора контейнеров приложения используйте команду \texttt{docker-compose rm}.



\subsection{Работа с ключами и сертификатами}

Создать ключ и сертификаты можно с помощью утилиты \texttt{openssl}. Создадим корневой ключ
\begin{lstlisting}[
style = bash,
numbers = none
]
$ openssl genrsa -out rootCA.key 2048
\end{lstlisting}

Теперь на основе ключа можно сгенерировать сертификат
\begin{lstlisting}[
style = bash,
numbers = none
]
$ openssl req -x509 -new -key rootCA.key -days 10000 -out rootCA.crt
\end{lstlisting}

Ключ
\begin{lstlisting}[
style = bash,
numbers = none
]
$ cat rootCA.key
# выведет
-----BEGIN RSA PRIVATE KEY-----
MIIEpQIBAAKCAQEA1LAK3Os5wgbTFNGzfqbVTbqjv2ExRI0jvS/wHwIWrPuR19K4
4TPegK8dM5DaNbWLCs0Lynp4OuWIUt56MLyH1Ewu9xynycOzRP40otmUGtain8HL
TqPMgA2vvVUA3JbFuN1wsyI9mCdxkSbLH5jwKslkWw9tUPP9k+Mi6NAFF3/RNMPw
5agJqp05M+9AnlgNchqosMxomdQpkXLZuTr7zWrk5vjXksrvszM4nJABGrbrGTnz
ZK51aW7brt023fnxU3HwhmkKthvE8oYhyM23c6G+Ti2zpdI8ILlCMfC/rdKJUmEX
vjuM98zUudxTH6MFVkX8Vq4OUxaVmisXWviGAwIDAQABAoIBAQCkbuY3HnUtGPGg
qu/G/1zyF1X55D6e7S+wWJugnZDCdEyxO21MTzm666f78gWCeLTiyNxQ0paZklPv
HaoCe//Xln7I9hKS3wZ+VLqFHQpwJXjdYoq4ZdL5PZudGVbtNHPxFOLI27QbKoOW
4RMxfqBPtBwueqLdb4WhDH402H7XRsWb9t+bTVtb7agtcjPAvZoV8x5EHlj3LErO
...
-----END RSA PRIVATE KEY-----
\end{lstlisting}

Сертификат
\begin{lstlisting}[
style = bash,
numbers = none
]
$ cat rootCA.crt
# выведет
-----BEGIN CERTIFICATE-----
MIID9zCCAt+gAwIBAgIUB/wdkhR8j3McjC1vNr/0elcPLoMwDQYJKoZIhvcNAQEL
BQAwgYoxCzAJBgNVBAYTAlJVMQ8wDQYDVQQIDAZNb3Njb3cxDzANBgNVBAcMBk1v
c2NvdzEQMA4GA1UECgwHR2F6cHJvbTEQMA4GA1UECwwHT2lsJkdhczELMAkGA1UE
AwwCQ0ExKDAmBgkqhkiG9w0BCQEWGWxlb3IuZmlua2VsYmVyZ0B5YW5kZXgucnUw
HhcNMjAwNjA0MTk1NDAzWhcNNDcxMDIxMTk1NDAzWjCBijELMAkGA1UEBhMCUlUx
DzANBgNVBAgMBk1vc2NvdzEPMA0GA1UEBwwGTW9zY293MRAwDgYDVQQKDAdHYXpw
cm9tMRAwDgYDVQQLDAdPaWwmR2FzMQswCQYDVQQDDAJDQTEoMCYGCSqGSIb3DQEJ
ARYZbGVvci5maW5rZWxiZXJnQHlhbmRleC5ydTCCASIwDQYJKoZIhvcNAQEBBQAD
ggEPADCCAQoCggEBANSwCtzrOcIG0xTRs36m1U26o79hMUSNI70v8B8CFqz7kdfS
uOEz3oCvHTOQ2jW1iwrNC8p6eDrliFLeejC8h9RMLvccp8nDs0T+NKLZlBrWop/B
y06jzIANr71VANyWxbjdcLMiPZgncZEmyx+Y8CrJZFsPbVDz/ZPjIujQBRd/0TTD
8OWoCaqdOTPvQJ5YDXIaqLDMaJnUKZFy2bk6+81q5Ob415LK77MzOJyQARq26xk5
82SudWlu267dNt358VNx8IZpCrYbxPKGIcjNt3Ohvk4ts6XSPCC5QjHwv63SiVJh
...
-----END CERTIFICATE-----
\end{lstlisting}

Прочитать сертификат
\begin{lstlisting}[
style = bash,
numbers = none
]
$ openssl x509 -in rootCA.crt -text
# выведет
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            07:fc:1d:92:14:7c:8f:73:1c:8c:2d:6f:36:bf:f4:7a:57:0f:2e:83
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: C = RU, ST = Moscow, L = Moscow, O = Gazprom, OU = Oil&Gas, CN = CA, emailAddress = leor.finkelberg@yandex.ru
        Validity
            Not Before: Jun  4 19:54:03 2020 GMT
            Not After : Oct 21 19:54:03 2047 GMT
        Subject: C = RU, ST = Moscow, L = Moscow, O = Gazprom, OU = Oil&Gas, CN = CA, emailAddress = leor.finkelberg@yandex.ru
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
            RSA Public-Key: (2048 bit)
            Modulus:
                00:d4:b0:0a:dc:eb:39:c2:06:d3:14:d1:b3:7e:a6:
                d5:4d:ba:a3:bf:61:31:44:8d:23:bd:2f:f0:1f:02:
                16:ac:fb:91:d7:d2:b8:e1:33:de:80:af:1d:33:90:
                da:35:b5:8b:0a:cd:0b:ca:7a:78:3a:e5:88:52:de:
                7a:30:bc:87:d4:4c:2e:f7:1c:a7:c9:c3:b3:44:fe:
...
\end{lstlisting}

Генерируем приватный ключ для \texttt{registry}
\begin{lstlisting}[
style = bash,
numbers = none
]
$ openssl genrsa -out registry.key 2048
\end{lstlisting}

И по ключу создаем запрос сертификата с помощью
\begin{lstlisting}[
style = bash,
numbers = none
]
$ openssl req -new -key registry.key -out registry.csr
\end{lstlisting}

Подписываем корневым сертификатом ключ, который потом надо будет отдать серверу
\begin{lstlisting}[
style = bash,
numbers = none
]
openssl x509 -req -in registry.csr -CA rootCA.crt -CAkey rootCA.key -CAcreateserial -out registry.crt -days 5000
# будет создан registry.crt
\end{lstlisting}

Файл \texttt{docker-compose.yml} будет выглядеть так
\begin{lstlisting}[
style = bash,
numbers = none
]
registry:
    restart: always
    image: registry:2
    ports:
        - 443:5000
    environment:
        REGISTRY_HTTP_ADDR: 0.0.0.0:5000
        REGISTRY_HTTP_HOST: https://registry.kis.im
        REGISTRY_HTTP_TLS_CERTIFICATE: /path/to/registry.crt
        REGISTRY_HTTP_TLS_KEY: /path/to/registry.key
    volumes:
        - /path/data:/var/lib/registry
        - /etc/cers:/etc/certs
\end{lstlisting}

Скачаем образ и поместим его в \texttt{registry}
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker pull alpine:latest
# перетегируем
$ docker tag alpine:latest registry.kis.im/leorfinkelberg/alpine:dev
\end{lstlisting}

Теперь можно отправить перетегированный образ в репозиторий
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker push registry.kis.im/leorfinkelberg/alpine:dev
\end{lstlisting}

Docker может не доверять самоподписанным сертификатам. Чтобы Docker доверял самоподписанным сертификатам нужно создать в \verb|/etc/| приведенную ниже цепочку каталогов и поместить туда сертификат, т.е.
\begin{lstlisting}[
style = bash,
numbers = none
]
$ cat /etc/docker/certs.d/registry.kis.im/ca.crt
...
\end{lstlisting}

Теперь можно скачивать
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker pull registry.kis.im/leorfinkelberg/alpine:dev
\end{lstlisting}

\subsection{Организация собственного реестра}

Простейшим способом создания \emph{локального реестра} является использование официального образа
\begin{lstlisting}[
style = bash,
numbers = none
]
docker run -d -p 5000:5000 registry:2
\end{lstlisting}

Теперь у нас есть работающий реестр, и можем присваивать образам соответствующие теги и выгружать их в этот реестр. При использовании механизма docker-machine остается возможность указания адреса localhost.
\begin{lstlisting}[
style = bash,
numbers = none
]
# создаем псевдоним для образа amouat/identidock:0.1 в пространстве имен localhost:5000
$ docker tag amouat/identidock:0.1 localhost:5000/identidock:0.1
$ docker push localhost:5000/identidock:0.1
\end{lstlisting}

Если сейчас удалить локальную версию, то в любой момент можно извлечь ее из локального реестра
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker rmi localhost:5000/identidock:0.1
$ docker pull localhost:5000/identidock:0.1
\end{lstlisting}

Образы можно извлекать по дайджесту\footnote{Уникальное хэш-значение на основании содержимого образа и его метаданных}
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker pull localhost:5000/identidock@sha256:d20...45345
\end{lstlisting}

Главным преимуществом использования дайджеста является абсолютная гарантия того, что извлекается в точности тот образ, который нужен пользователю. При извлечении (загрузке) по тегу можно оказаться в ситуации, когда имя тегированного образа было изменено, а пользователь об этом не знает.

Главное обоснование использования частного (локального) реестра -- необходимость организации централизованного хранилища для группы разработчиков или всей организации. Это означает, что потребуется возможность загрузки образов из реестра, выполняемая удаленным демоном Docker. Но при попытке обращения к локальному реестру из вне, будет получена ошибка <<Error response from daemon: unable to ping registry endpoint>>.

Попробуем разобраться в том, что произошло. Демон Docker запретил соединение с удаленным хостом, так как этот хост не имеет действительного сертификата TLS (Transport Layer Security). До этого установление соединения разрешалось только потому, что в механизме Docker предусмотрено особое исключение для загрузки с серверов, расположенных на локальном хосте (то есть по адресу localhost).

Возникшую проблему можно решить одним из трех способов:
\begin{itemize}
	\item перезапустить каждый демон Docker, которому требуется доступ к нашему реестру с аргументом \verb|--insecure-registry 192.168.1.100:5000|\footnote{Разумеется нужно указывать адрес и номер порта, который вы выбрали для своего сервера},
	
	\item установить на хосте реестра подписанный сертификат от аккредитованного центра сертификации,
	
	\item установить на хосте реестра самоподписанный сертификат и скопировать его на все хосты демонов Docker, которым должен быть предоставлен доступ к этому реестру.
\end{itemize}

Для создания собственного \emph{самоподписанного сертификата} можно воспользоваться утилитой OpenSSL. Все операции должны быть выполнены на компьютере, который предполагается использовать в качестве сервера в течение длительного времени
\begin{lstlisting}[
style = bash,
numbers = none
]
~$ mkdir registry_certs
~$ openssl req -newkey rsa:4096 -nodes -sha256 -keyout registry_certs/domain.key -x509 \
-days 365 -out registry_certs/domain.crt
\end{lstlisting}

Здесь создается самоподписанный сертификат x509 и 4096-битный закрытый ключ по алгоритму RSA. Сертификат подписан с помощью дайджеста SHA256 и действителен в течение 365 дней. После завершения процесса мы получаем файл сертификата \texttt{domain.crt}, который будет совместно использоваться всеми клиентами, и закрытый ключ \texttt{domain.key}, который следует хранить в безопасном месте, исключив возможность постороннего доступа к нему.

Теперь необходимо скопировать сертификат в каждую систему демона Docker, которому потребуется доступ к реестру. Копирование должно быть выполнено в файл
\begin{lstlisting}[
style = bash,
numbers = none
]
/etc/docker/certs.d/<адрес_реестра>/ca.crt
\end{lstlisting}
где \verb|<адрес_реестра>| -- это адрес (имя) и номер порта конкретного сервера реестра. Также потребуется перезапустить демон Docker. Например
\begin{lstlisting}[
style = bash,
numbers = none
]
~$ sudo mkdir -p /etc/docker/certs.d/reginald:5000
~$ sudo cp registry_certs/domain.crt /etc/docker/certs.d/reginald:5000/ca.crt
~$ sudo service docker restart
\end{lstlisting}

Теперь можно запустить реестр
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker run -d -p 5000:5000 -v $(pwd)/registry_certs:/certs \
    -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \
    -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \
    --restart=always  --name registry registry:2
\end{lstlisting}

Здесь подкаталог \texttt{registry\_certs} файловой системы хоста монтируется на каталог \texttt{/certs} внутри контейнера. Таким образом из-под каталога \texttt{/certs} внутри контейнера будут доступны \texttt{*.crt} и \texttt{*.key}.

Выполним операции извлечения образа, замены его тега и возврата (выгрузки) обратно в реестр, чтобы убедиться в работоспособности нового реестра
\begin{lstlisting}[
style = bash,
numbers = none
]
root@reginald:~$ docker pull debian:wheezy
root@reginald:~$ docker tag debian:wheezy reginlad:5000/debian:local
root@reginald:~$ docker push reginald:5000/debian:local
\end{lstlisting}

Итак, мы получили реестр с возможностью удаленного доступа к нему с обеспечением безопасной работы и безопасного хранения образов. При тестировании реестра с удаленных компьютеров не забудьте скопировать сертификаты в файл \texttt{/etc/docker/certs.d/<адрес\_реестра>/ca.crt} на компьютерах с работающими механизмами Docker.

\paragraph{Хранилище} По умолчанию образ реестра использует драйвер файловой системы, который вполне ожидаемо сохраняет все данные и образы в соответствующей файловой системе.

\subsection{Сокращение размера образа}

Образ формируется из нескольких уровней, причем каждый уровень создается отдельной командой из соответствующего файла Dockerfile и его родительских файлов Dockerfile. Общий конечный размер образа представляет собой сумму размеров всех его уровней.

Если файл удаляется на том же уровне, на котором он создается, то такой файл не включается в образ. Поэтому часто встречаются файлы Dockerfile, которые загружают tar-архивы или архивы других форматов, распаковывают их и сразу же удаляют архивный файл в одной инструкции \texttt{RUN}. Например, в официальный образ MongoDB включена следующая инструкция
\begin{lstlisting}[
style = bash,
numbers = none
]
RUN curl -SL "https://${MONGO_VERSION}.tgz" -o mongo.tgz \
    && curl -SL "https://${MONGO_VERSION}.tgz.sig" -o mongo.tgz.sig \
    && gpg --verify mongo.tgz.sig && tar -xvf mongo.tgz -C /usr/local --strip-components=1 \
    && rm mongo.tgz*
\end{lstlisting}


\section{Базовые концепции, связанные с системой Docker}

\subsection{Структура стека протоколов TCP/IP}

Сегодня стек протоколов TCP/IP используется как в глобальных, так и в локальных сетях. Стек имеет иерархическую, четырхуровневую структуру (см~\tblref{tab:tcpip}).

Прикладной уровень стека TCP/IP соответствует трем верхним уровням модели OSI: прикладному, представления и сеансовому \cite{olifer:compnets-2020}.

\begin{table}[h]
	\centering
	\caption{\itshape Иерархическая структура стека протоколов TCP/IP}\label{tab:tcpip}
	%\renewcommand{\arraystretch}{1.05}
	\begin{tabular}{cl}
		\rowcolor[gray]{0.96} {Прикладной уровень} & FTP, Telnet, HTTP, SMTP, SNMP, TFTP \\
		Транспортный уровень & TCP, UDP \\
		\rowcolor[gray]{0.96} {Сетевой уровень} & IP, ICMP, RIP, OSPF \\
		Уровень сетевых интерфейсов & не регламентируется
	\end{tabular}
\end{table}

Протоколы прикладного уровня развертываются на хостах.

Транспортный уровень стека TCP/IP может предоставлять вышележащему уровню два типа сервиса:

\begin{itemize}
	\item гарантированную доставку обеспечивает \emph{протокол управления передачей} (Transmission Control Protocol, TCP),
	
	\item доставку по возможности, или с максимальными усилиями, обеспечивает \emph{протокол пользовательских дейтаграмм} (User Datagram Protocol, UDP).
\end{itemize}

Чтобы обеспечить надежную доставку данных, протокол TCP предусматривает установление \emph{логического соединения}. Это позволяет нумеровать пакеты, подтверждать их прием квитанциями, организовать в случае потери повторные передачи, распознавать и уничтожать дубликаты, доставлять прикладному уровню пакеты в том порядке, в котором они были отправлены. Благодаря этому протоколу объекты на \emph{хосте-отправителе} и \emph{хосте-получателе} могут поддерживать обмен данными в дуплексном режиме. TCP дает возможность без ошибок доставить сформированный на одном из компьютеров поток байтов на любой другой компьютер, входящий в составную сеть.

Протокол UDP является простейшим \emph{дейтаграммным} протоколом, используемым, если задача надежного обмена данными либо вообще не ставится, либо решается средствами более высокого уровня -- прикладным уровнем или пользовательским приложением.

В функции протоколов TCP и UDP входит также исполнение роли связующего звена между прилегающими к транспортному уровню прикладным и сетевым уровням. От прикладного протокола (например, от HTTP) транспортный уровень принимает задание на передачу данных с тем или иным качеством прикладному уровню-получателю.

Сетей уровень, называемый также уровнем Интернета, является стрежнем всей архитектуры TCP/IP. Протоколы сетевого уровня поддерживают интерфейс с вышележащим транспортным уровнем, получая от него запросы на передачу данных по составной сети, а также с нижележащим уровнем сетевых интерфейсов.

Основным протоколом сетевого уровня является межсетевой протокол (Internet Protocol, IP). В его задачу входит продвижение пакета между сетями -- от одного маршрутизатора к другому до тех пор, пока пакет не попадет в сеть назначения. В отличие от протоколов прикладного уровня и транспортного уровней, протокол IP развертывается не только на хостах, но и на всех маршрутизаторах. Протокол IP -- это дейтаграммный протокол, работающий без установления соединения по принципу доставки с максимальными усилиями. Такой тип сетевого сервиса называют также <<ненадежным>>.

\subsection{Формат IP-адреса}

В заголовке IP-пакета предусмотрены поля для хранения \emph{IP-адреса отправителя} и \emph{IP-адреса получателя}. Каждое из этих полей имеет фиксированную длину 4 байта (32 бита).

IP-адрес состоит из двух логических частей -- номера сети и номера узла в сети. Наиболее распространенная форма представления IP-адреса -- запись в виде четырех чисел, представляющих значения каждого байта в десятичной форме и разделенных точками, например: 128.10.2.30.

Границу в IP-адресе между номером сети и номером узла в сети можно найти с помощью \emph{маски}. Маска -- это число, применяемое в паре с IP-адресом, причем двоичная запись маски содержит непрерывную последовательность единиц в тех разрядах, которые должны в IP-адресе интерпретироваться как номер сети. Граница между последовательностями единиц и нулей в маске соответствует границе между номером сети и номером узла в IP-адресе.

\subsection{Виртуальный сетевой интерфейс}

Все TCP/IP-реализации поддерживают loopback-механизмы, которые реализуют виртуальный сетевой интерфейс исключительно программно и не связанны с каким-либо оборудованием, но при этом полностью интегрированны во внутреннюю сетевую инфраструктуру компьютерной системы. Пожалуй самый распространенным IP-адресом в механизмах loopback является \texttt{127.0.0.1}. В IPv4 в него также отображается любой адрес из диапазона \texttt{127.0.0.0} -- \texttt{127.255.255.255}. IPv6 определяет единственные адрес для этой функции -- \texttt{0:0:0:0:0:0:0:1/128} (так же записывается как \texttt{::1/128}). Стандартное, официально зарезервированное доменное имя для этих адресов -- \texttt{localhost}.

Интерфейс loopback имеет несколько путей применения. Он может быть использован сетевым клиентским программным обеспечением, чтобы общаться с серверным приложением, расположенным на том компьютере. То есть если на компьютере, на котором запущен веб-сервер, указать в веб-браузере URL \texttt{http://127.0.0.1/} или \texttt{http:/localhost/}, то он попадает на веб-сайт этого компьютера.



\section{Пример создания простого web-приложения}

Структура проекта \cite[\strbook{99}]{mouat:docker-2017}
\begin{lstlisting}[
style = cmd,
numbers = none
]
indentidock/
    -- Dockerfile
    -- app/
        -- identidock.py
    -- cmd.sh
    -- docker-compose.yml
\end{lstlisting}

Python-приложение будет выглядеть так
\begin{lstlisting}[
style = ironpython,
title = {\sffamily app/identidock.py},
emph = {mainpage, get_identicon},
numbers = none
]
from flask import Flask, Response, request
import requests
import hashlib
import redis

app = Flask(__name__)
cache = redis.StrictRedis(host='redis', port=6379, db=0)
salt = 'UNIQUE_SALT'
default_name = 'Leor Finkelberg'

@app.route('/', methods=['GET', 'POST'])
def mainpage():
    name = default_name
    if request.method == 'POST':
        name = request.form['name']

        salted_name = salt + name
        name_hash = hashlib.sha256(salted_name.encode()).hexdigest()
        header = '<html><head><title>Identidock</title></head><body>'
        body = '''<form method='POST'>
                      Hell <input type='text' name='name' value='{0}'>
                      <input type='submit' value='submit'>
                  </form>
                  <p>You look like a:
                  <img src='/monster/{1}'/>
               '''.format(name, name_hash)
    footer = '</body></html>'

    return header + body + footer


@app.route('/monster/<name>')
def get_identicon(name):
    image = cache.get(name)
    if image is None:
        print('Cache miss', flush=True)
        r = requests.get('http://dnmonster:8080/monster/' + name + '?size=80')
        image = r.content
        cache.set(name, image)

    return Response(image, mimetype='image/png')


if __name__ == '__main__':
    app.run(debug = True, port = 5000)
\end{lstlisting}

bash-сценарий управляет режимами запуска приложения
\begin{lstlisting}[
style = bash,
title = {\sffamily ./cmd.sh},
numbers = none
]
#!/bin/bash

exit_on_signal_SIGINT () {
    echo "Script interrupted." 2>&1
    exit 0  # << для того чтобы прекратить выполнение программы!
}

# будет реагировать на прерывание
trap exit_on_signal_SIGINT SIGINT

if [[ "$ENV" == 'DEV' ]]; then
    echo 'Running Development Server'
    exec python 'identidock.py'
elif [[ "$ENV" == 'UNIT' ]]; then
    echo 'Running Unit Tests'
    exec python 'test.py'  # файл test.py должен размещаться в app/
else
    echo 'Running Production Server'
    ...
fi
\end{lstlisting}

\begin{lstlisting}[
style = bash,
title = {\sffamily ./Dockerfile},
numbers = none
]
FROM python:3.5

RUN groupadd -r uwsgi && useradd -r -g uwsgi uwsgi
RUN pip install Flask==1.1.1 gunicorn==20.0.0 requests==2.22.0 redis==3.5.0
WORKDIR /app
COPY app /app
COPY cmd.sh /

EXPOSE 9090 9191
USER uwsgi

CMD ["/cmd.sh"]
\end{lstlisting}

Запустить приложение в режиме тестирования можно так
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker build -t identidock .  # создать образ на основе Dockerfile
$ docker run -e ENV=UNIT identidock
\end{lstlisting}

\begin{lstlisting}[
style = bash,
title = {\sffamily ./docker-compose.yml},
numbers = none
]
identidock:
    build: .
    ports: 
        - "5000:5000"
    environment:
        ENV: DEV
    volumes:
        - "./app:/app"
    links:
        - dnmonster
        - redis

dnmonster:
    image: amouat/dnmonster:1.0

redis:
    image: redis:alpine3.12
\end{lstlisting}

\section{Пример работы с базой данных Redis}

Redis -- \emph{резидентная} система управления базами данных\footnote{Организованная в оперативной памяти} класса NoSQL, работающая со структурами данных типа <<ключ-значение>>.

Рассмотрим пример взаимодействия с СУБД Redis на базе концепции Docker-контейнеров. Для начала скачаем образ Redis
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker pull redis
$ docker images
# выведет
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
redis               latest              36304d3b4540        9 days ago          104MB
\end{lstlisting}

Для того чтобы подготовить <<основу>> для работы с СУБД Redis, запустим контейнер на базе образа Redis в фоновом режиме и присвоим этому образу имя <<myredis>>
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker run -d --name myredis redis
$ docker ps -a  # 0671bf41b781180da2c6341875fae93d484f8df3f54bb25569220f83936fd032
# выведет
CONTAINER ID  IMAGE  STATUS       ... PORTS     NAMES
0671bf41b781  redis  Up 3 seconds ... 6379/tcp  myredis
\end{lstlisting}

Теперь для того чтобы получить доступ к контейнеру \texttt{myredis} нужно создать новый временный контейнер (контейнер, который будет уничтожен после завершения его процесса\footnote{Контейнер существует пока существует его основной процесс \cite{mouat:docker-2017}}), который будет выступать в роли интерфейса к СУБД Redis. С помощью этого контейнера мы сможем записать данные в базу, ассоциированную с контейнером \texttt{myredis}
\begin{lstlisting}[
numbers = none
]
# обязательно нужно указать /bin/bash
$ docker run -it --rm --link myredis:redis redis /bin/bash
root@5cab704887ff:/data# redis-cli -h redis -p 6379
redis:6379> set "Ansys" "MAPDL"  # OK
redis:6379> set "Nastran" "Python"  # OK
...
redis:6379> save  # OK
redis:6379> exit
root@5cab704887ff:/data# exit
\end{lstlisting}

Здесь: флаг \verb|-it| означает создать интерактивный сеанс работы на подключаемом терминальном устройстве; ключ \verb|--rm| означает удалить контейнер как только завершиться его процесс; ключ \verb|--link myredis:redis| означает создать связь между текущим контейнером и контейнером с именем \texttt{myredis} (\texttt{redis} -- это просто псевдоним, через который можно обращаться к контейнеру \texttt{myredis} из-под текущего контейнера).

С помощью терминального клиента \texttt{redis-cli} подключаемся к СУБД Redis, указывая хост и порт, и создаем несколько пар <<ключ-значение>>. Затем сохраняет наработки и завершаем сеанс.

Остается только перенести базу данных из контейнера на локальную машину. Для этого запускаем еще один контейнер. Теперь на базе образа какой-нибудь UNIX-подобной операционной системы, например, Ubuntu и копируем файл базы данных \texttt{dump.rdb} в каталог файловой системы хоста \texttt{backup\_host}
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker run -it --rm --volumes-from myredis -v $(pwd)/backup_host:/backup_cont ubuntu
\end{lstlisting}

В контейнере будет создан каталог \texttt{backup\_cont}, который связан с каталогом файловой системы хоста \texttt{backup\_host}. Говорят, что каталог \texttt{backup\_host} файловой системы хоста смонтирован на каталог \texttt{backup\_cont} внутри контейнера. Файлы, который попадают в каталог \texttt{backup\_cont} внутри контейнера оказываются в каталоге \texttt{backup\_host}. Ключ \verb|--volumes-from| позволяет получить доступ к каталогу базы данных Redis.

Если теперь вывести содержание корневой директории контейнера, то среди прочих каталогов и файлов мы увидим каталог \texttt{data} и \texttt{backup\_cont}
\begin{lstlisting}[
numbers = none
]
root@3cc5e757c42f:/# ls -l
# выведет
total 52
drwxr-xr-x   2 root root   80 Jun  7 20:18 backup_cont
lrwxrwxrwx   1 root root    7 Apr 23 11:06 bin -> usr/bin
drwxr-xr-x   2 root root 4096 Apr 15 11:09 boot
drwxr-xr-x   2  999  999 4096 Jun  7 22:42 data
drwxr-xr-x   5 root root  360 Jun  7 22:54 dev
drwxr-xr-x   1 root root 4096 Jun  7 22:54 etc
drwxr-xr-x   2 root root 4096 Apr 15 11:09 home
...
\end{lstlisting}

Скопируем файл базы данных в \texttt{backup\_cont}
\begin{lstlisting}[
numbers = none
]
root@3cc5e757c42f:/# cp -ip data/dump.rdb backup_cont/
\end{lstlisting}

После копирования этот файл можно будет найти в каталоге \texttt{backup\_host}. Когда работа с контейнером Redis будет закончена, его можно остановить и удалить
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker stop myredis
$ docker rm -v myredis  # `-v` означает удалить контейнер вместе с томами
\end{lstlisting}

Вспомогательные контейнеры можно удалить с помощью команды
\begin{lstlisting}[
style = bash,
numbers = none
]
$ docker rm $(docker ps -aq)
\end{lstlisting}


\section{Наиболее полезные конструкции}

\subsection{Манипуляции с контейнерами}

Запустить контейнер с именем \texttt{leorcont}, создав сеанс интерактивной работы (\texttt{-i}) на подключаемом терминальном устройстве (\texttt{-t}) tty, и вызывать командную оболочку \texttt{bash} из-под ОС~\texttt{Ubuntu Linux}

\begin{lstlisting}[
numbers = none
]
docker run -it --name leorcont ubuntu bash
\end{lstlisting}

Запустить контейнер, а после остановки удалить сам контейнер и созданную на время его существования файловую систему

\begin{lstlisting}[
numbers = none
]
docker run --rm -it ubuntu bash
\end{lstlisting}

Перезапустить остановленный контейнер

\begin{lstlisting}[
numbers = none
]
docker start quizzical_wright
\end{lstlisting}

\subsection{Информация о контейнере}

Получить информацию о контейнере

\begin{lstlisting}[
numbers = none
]
docker inspect quizzical_wright
\end{lstlisting}

Вывести информацию о контейнере с использованием утилиты \texttt{grep}

\begin{lstlisting}[
numbers = none
]
docker inspect quizzical_wright | grep SandboxID
\end{lstlisting}

Вывести информацию о контейнере с использованием шаблона языка \texttt{Go} \url{https://metanit.com/go/web/2.2.php}

\begin{lstlisting}[
numbers = none
]
docker inspect --format {{.NetworkSettings.SandboxID}} quizzical_wright
\end{lstlisting}

Вывести список файлов в работающем контейнере. Для контейнеров \texttt{Docker} использует файловую систему \texttt{UnionFS}, которая позволяет монтировать несколько файловых систем в общую иерархию, которая выглядит как \emph{единая файловая система}. Файловая система конкретного \emph{образа} смонтирована как уровень \emph{только для чтения}, а любые изменения в работающем контейнере происходят на уровне с разрешенной записью, монтируемого поверх основной {файловой системы образа}. Поэтому \texttt{Docker} при поиске изменений в работающей системе должен рассматривать только самый верхний уровень, на котором возможна запись \cite{mouat:docker-2017}

\begin{lstlisting}[
numbers = none
]
docker diff quizzical_wright
\end{lstlisting}

Вывести список работающих контейнеров

\begin{lstlisting}[
numbers = none
]
docker ps
\end{lstlisting}

Вывести список всех контейнеров, включая остановленные (stopped)\footnote{Формально их называют контейнерами, из которых был совершен выход (exited containers)}. Такие контейнеры могут быть перезапущены с помощью \texttt{docker start}

\begin{lstlisting}[
numbers = none
]
docker ps -a
\end{lstlisting}

\subsection{Удаление контейнеров и образов}

Удалить контейнер 

\begin{lstlisting}[
numbers = none
]
docker rm quizzical_wright
\end{lstlisting}

Удалить несколько остановленных контейнеров можно следующим способом. Значение флагов: \texttt{-a} (все контейнеры), \texttt{-q} (вывести только числовой идентификатор контейнера), \texttt{-f} (фильтр), \texttt{-v} (все тома, на которые не ссылаются какие-либо другие контейнеры)

\begin{lstlisting}[
numbers = none
]
docker rm -v $(docker ps -aq -f status=exited)
\end{lstlisting}

Удалить все образы 
\begin{lstlisting}[
style = bash,
numbers = none
]
docker rmi $(docker images | sed '1d' | awk -F ' ' '{ print $3 }')
\end{lstlisting}

\section{Docker для ML}

Данных не должно быть в docker-образе. Данные должны подгружаться при запуске контейнера. Docker-образ можно запускать с помощью Airflow. Оркестратор Airflow скачает docker-образ и запустит его. Можно настроить запуск по расписанию с помощью Kubernetes.

Docker registry не предназначен для хранения больших файлов, поэтому лучше тяжелые python-сценарии, которые требуют тяжелых библиотек (PyTorch, TF etc), не размещать в docker-образе. Модель может храниться, например, в облачном хранилище S3. Это хранилище прекрасно приспособлено для долгого хранения больших файлов. Кроме того, если docker-образ тяжелый, то он дольше скачивается и дольше разворачивается.

\subsection{Полное руководство по созданию Docker-образа для обслуживания системы машинного обучения в продакшене}

Источник: \url{https://habr.com/ru/company/mailru/blog/548480/}

Важные замечания:
\begin{itemize}
	\item Файл \texttt{requirements.txt} всегда должен содержать \emph{версию пакета} Python. Никогда не пишите просто название пакета, иначе всегда будут устанавливаться последняя версия пакета, а пользы от Docker в таком случае не будет никакой,
	
	\item Всегда группируйте похожие команды \texttt{RUN}, которые оперируют на одном уроне Docker. Например
\begin{lstlisting}[
style = bash,
numbers = none	
]
RUN apt update && \
apt install --no-install-recommends -y build-essential \
gcc curl ca-certificates python3 && \
apt clean && rm -rf /var/lib/apt/lists/*
\end{lstlisting}

   \item Используйте с \texttt{pip} флаг \verb|--no-cache-dir| в качестве целевой эксплуатационной среды
\begin{lstlisting}[
style = bash,
numbers = none	
]
RUN pip install --no-cache-dir --user -r /req.txt
\end{lstlisting}

    \item Используйте \texttt{.dockerignore}, чтобы избежать ненужного контекста сборки. Это работает так же, как \texttt{.gitignore}
    
    \item Когда это возможно используйте slim-версию базового образа, например, \texttt{python:buster-slim} etc.
    
    \item Избегайте базовых Docker-образов на основе Alpine (они плохо работают с Python).
\end{itemize}

\paragraph{Одноэтапная сборка образа}

Во время одного процесса сборки будут выполнены все задачи. Последовательность действий: выберете базовый образ, установите пакеты ОС, скопируйте исходники, установите пакеты, задайте точку входа (если нужно) или другие команды.

Пример одноэтапной сборки

\begin{minipage}[t]{0.55\textwidth}
	\begin{lstlisting}[
	title = {\sffamily Dockerfile},
	style = bash,
	numbers = none	
	]
	FROM python:3.8-slim
	
	RUN apt update && \
	  apt install --no-install-recommends -y \
	  build-essential gcc && \
	  apt clean && rm -rf /var/lib/apt/lists/*
	  
	COPY ./req.txt /req.txt
	COPY ./src /src
	
	RUN pip3 install --no-cache-dir -r /req.txt
	CMD ["python3", "/src/app.py"]
	
	EXPOSE 8080
	\end{lstlisting}
\end{minipage}
\hspace*{5mm}
\begin{minipage}[t]{0.4\textwidth}
	\begin{lstlisting}[
	title = {\sffamily req.txt},
	style = bash,
	numbers = none	
	]
	tensorflow==2.2.0
	scikit-learn==0.24.1
	pytest==6.2.2
	pandas==1.2.1
	...
	\end{lstlisting}
\end{minipage}

Одноэтапная сборка очень проста и подходит для многих сценариев. Это нормальная практика, но у нее есть фундаментальные недостатки, особенно с точки зрения проектов на Python. Важно с \texttt{apt} использовать флаг \verb|--no-install-recommends|, а с \texttt{pip} -- флаг \verb|--no-cache-dir|. Нам не нужно сохранять кэш, потому что он не нужен ни для среды разработки, ни для эксплуатационной среды. Если вы используете какую-нибудь CI/CD-платформу (вроде Github action), с ограниченным размером хранилища, то она будет работать только если используются описанные флаги.

Библиотеки Python из коробки не работают, сначала их нужно скомпилировать на C. Нас интересует лишь скомпилированная часть библиотек, остальное не нужно. При выполнении \texttt{pip install} все библиотеки \emph{сначала скачиваются}, а \emph{затем компилируются}.

Нужно удалить все промежуточные и дополнительные компоненты, созданные при установке библиотек. Для этого можно использовать bash-команды. Однако есть вероятность все сломать. Исправить ситуацию может многоэтапная сборка (Docker multi-stage builds).

\paragraph{Многоэтапная сборка} Это один из самых эффективных методов оптимизации, сохраняющий удобство чтения и сопровождения образов.

При многоэтапной сборке используется несколько инструкций \texttt{FROM}. Каждая такая инструкция может оперировать разными базовыми образами (каждая инструкция \texttt{FROM} начинает новый этап сборки). Можно выборочно копировать артефакты из одного этапа в другой, отбрасывая все, что вам не нужно конечном образе.

Пример
\begin{lstlisting}[
title = {\sffamily Dockerfile},
style = bash,
numbers = none	
]
# Stage 1: Builder/Compiler
FROM python:3.7-slim as builder # builder -- это имя этапа
RUN apt update && \
  apt install --no-install-recommends -y \
  build-essential gcc
COPY req.txt /req.txt

# флаг --user очень важен! без него не работает `COPY --from` с указанными ниже путями
RUN pip install --no-cache-dir --user -r /req.txt

# Stage 2: Runtime
FROM debian:buster-slim
RUN apt update && \
  apt install --no-install-recommends -y \
  build-essential python3 && \
  apt clean && rm -rf /var/lib/apt/lists/*
  
COPY --from=builder /root/.local/lib/python3.7/site-packages /usr/local/lib/python3.7/dist-packages
COPY ./src /src
CMD ["python3", "/src/app.py"]
EXPOSE 8080
\end{lstlisting}

Здесь команда \texttt{apt update} обновляет списки пакетов из репозиториев. Команда \texttt{apt install --no-install-recommends -y python3} устанавливает Python версии 3, отвечая на все возникающие вопросы да (\verb|-y|) и не устанавливая рекомендуемые пакеты.

На первом этапе устанавливаются библиотеки Python: они сначала скачиваются, а затем компилируются на C, для этого мы установили \texttt{gcc}. Затем мы просто копируем \emph{скомпилированные библиотеки} из первого этапа во второй с помощью этой команды
\begin{lstlisting}[
style = bash,
numbers = none	
]
COPY --from=<stage 1> stage1/src stage2/destination
\end{lstlisting}

В результате этих манипуляций размер образа уменьшится, но не сильно. С другими языками разница будет колоссальной, но у Python есть несколько фокусов:
\begin{itemize}
	\item сейчас многие библиотеки распространяются в виде предварительно скомпилированных whl-файлов (это формат wheel из PyPI), поэтому их компилировать не требуется,
	
	\item то есть в случае, когда библиотеки распространяются в виде предварительно скомпилированных файлов, многоэтапной сборке негде развернуться. Однако не все пакеты PyPI распространяются в скомпилированном виде; многие поставляются в формате \texttt{tar.gz} и их нужно сначала скомпилировать.
\end{itemize}

\paragraph{Сборка Docker-образа для любого проекта на Python (GPU)} Собирать docker-образ для CPU не трудно, чего не скажешь о сборке образа для GPU. Если ошибиться, то размер будет огромный.

TensorFlow и Pytorch используют видеодрайверы NVIDIA CUDA. Поэтому сначала нужно установить на хостовую машину свежие драйверы NVIDIA CUDA, а также соответствующую cuDNN.

После этого нужно установить \texttt{nvidia-docker2}, позволяющий движку Docker обращаться к видеодрайверам NVIDIA. Самое важное -- выбрать правильную версию/тег CUDA, cuDNN для NVIDIA-docker-образа, а также записать туда TensorFlow/Pytorch. Тогда система машинного обучения сможет использовать видеокарту.

Рекомендации
\begin{itemize}
	\item всегда используйте в docker-образе те же версии CUDA и cuDNN, что и на хостовой машине,
	
	\item не устанавливайте бездумно самую свежую версию библиотеки TensorFlow/Pytorch из PyPI. Не каждая версия этих пакетов будет работать с любой версией CUDA и cuDNN,
	
	\item самое важное: в docker-hub есть много образов NVIDIA, так что перед тем скачать ту или иную версию, нужно выяснить какая именно версия нужна (выбирать нужно версии, помеченные тегами base или runtime).
\end{itemize}

Для выбора тега есть эмпирическое правило
\begin{enumerate}
	\item проверить версию CUDA и cuDNN на хостовой машине: для примера, cudnn 7.6.5 и cuda10.1\_0,
	
	\item в зависимости от результатов шага 1 выбрать версию docker-образа, например, nvidia/cuda:10.1-cudnn7-runtime,
	
	\item выбрать правильную версию TensorFlow/Pytorch, которая совместима с вашей версией CUDA и cuDNN, например, TensorFlow 2.20. 
\end{enumerate}

Пример \emph{одноэтапной} сборки docker-образа (GPU)
\begin{lstlisting}[
style = bash,
numbers = none	
]
FROM nvidia/cuda:10.1-cudnn7-runtime

RUN apt update && \
  apt install --no-install-recommends -y build-essential software-properties-common && \
  add-apt-repository -y ppa:deadsnakes/ppa && \
  apt install --no-install-recommends -y python3.8 python3-pip python3-set uptools python3-distutils && \
  apt clean && run -rf /var/lib/apt/lists/*
  
COPY req.txt /req.txt
COPY ./src /src
RUN python3.8 -m pip install --upgrade pip && \
  python3.8 -m pip install --no-cache-dir --user -r /req.txt
CMD ["python3", "/src/app.py"]
EXPOSE 8080
\end{lstlisting}

Пример \emph{многоэтапной} сборки docker-образа (GPU)
\begin{lstlisting}[
style = bash,
numbers = none	
]
# Stage 1: Builder/Compiler
FROM python:3.8-slim as builder
RUN apt update && \
  apt install --no-install-recommends -y build-essential gcc
COPY req.txt /req.txt

RUN pip install --no-cache-dir --user -r /req.txt

# Stage 2: Runtime
FROM nvidia/cuda:10.1-cudnn7-runtime

RUN apt update && \
  apt install --no-install-recommends -y build-essential software-properties-common && \
  add-apt-repository -y ppa:deadsnakes/ppa && \
  apt install --no-install-recommends -y python3.8 python3-distutils && \
  update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 1 && \
  update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2 && \
  apt clean && rm -rf /var/lib/apt/lists/*
COPY --from=builder /root/.local/lib/python3.8/site-packages /usr/local/lib/python3.8/dist-packages
COPY ./src /src
CMD ["python3", "/src/app.py"]
EXPOSE 8080
\end{lstlisting}

ВАЖНО: всегда рекомендуется использовать многоэтапную сборку, она в любом случае улучшает читаемость.

Даже после сборки с соблюдением всех правил и советов нужно исследовать образ на возможность дополнительных улучшений. \texttt{Dive} \url{} -- прекрасный инструмент для исследования образа, содержимого слоев и поиска способов уменьшить размер Docker/OCI-образа.

У Dive есть две очень полезные метрики
\begin{itemize}
	\item возможная трата места на диске,
	
	\item оценка эффективности образа.
\end{itemize}

Но его лучшая возможность -- интеграция с любым CI-инструментом. Для обеих метрик можно указать условие, и если оно не выполняется, то и CI-задача тоже не выполняется. Поэтому мы всегда можем доверять docker-образу, созданному с помощью CI-задачи.

Когда \texttt{dive} запускается с переменной окружения \texttt{CI=true}, то вместо запуска интерфейса пользователя выполняется анализ docker-образа

\begin{lstlisting}[
style = bash,
numbers = none	
]
CI=true dive 0a2c..e7
\end{lstlisting}

На текущий момент поддерживается три метрики качества docker-образа, которые можно включить в файл \texttt{.dive-ci}. Сам файл \texttt{.dive-ci} должен находится в корне проекта
\begin{lstlisting}[
title = {\sffamily .dive-ci},
style = bash,
numbers = none	
]
rules:
	# If the efficiency is measured below X%, mark as failed.
	# Expressed as a ratio between 0-1.
	lowestEfficiency: 0.95

	# If the amount of wasted space is at least X or larger than X, mark as failed.
	# Expressed in B, KB, MB, and GB.
	highestWastedBytes: 20MB

	# If the amount of wasted space makes up for X% or more of the image, mark as failed.
	# Note: the base image layer is NOT included in the total image size.
	# Expressed as a ratio between 0-1; fails if the threshold is met or crossed.
	highestUserWastedPercent: 0.20
\end{lstlisting} 

Dive можно сконфигурировать с помощью файла \texttt{.dive.yaml}
\begin{lstlisting}[
title = {\sffamily .dive.yaml},
style = bash,
numbers = none	
]
# supported options are "docker" and "podman"
container-engine: docker
# continue with analysis even if there are errors parsing the image archive
ignore-errors: false
log:
	enabled: true
	path: ./dive.log
	level: info

# Note: you can specify multiple bindings by separating values with a comma.
# Note: UI hinting is derived from the first binding
keybinding:
	# Global bindings
	quit: ctrl+c
	toggle-view: tab
	filter-files: ctrl+f, ctrl+slash
	
	# Layer view specific bindings
	compare-all: ctrl+a
	compare-layer: ctrl+l

	# File view specific bindings
	toggle-collapse-dir: space
	toggle-collapse-all-dir: ctrl+space
	toggle-added-files: ctrl+a
	toggle-removed-files: ctrl+r
	toggle-modified-files: ctrl+m
	toggle-unmodified-files: ctrl+u
	toggle-filetree-attributes: ctrl+b
	page-up: pgup
	page-down: pgdn

diff:
# You can change the default files shown in the filetree (right pane). All diff types are shown by default.
	hide:
		- added
		- removed
		- modified
		- unmodified

filetree:
	# The default directory-collapse state
	collapse-dir: false

	# The percentage of screen width the filetree should take on the screen (must be >0 and <1)
	pane-width: 0.5

	# Show the file attributes next to the filetree
	show-attributes: true

layer:
	# Enable showing all changes from this layer and every previous layer
	show-aggregated-changes: false
\end{lstlisting}

Dive ожидает обнаружить конфигурационный файл \texttt{.dive.yaml} по следующим путям
\begin{itemize}
	\item \verb|$XDG_CONFIG_HOME/dive/*.yaml|,
	
	\item \verb|$XDG_CONFIG_DIRS/dive/*.yaml|,
	
	\item \verb|~/.config/dive/*.yaml|,
	
	\item \verb|~/.dive.yaml|.
\end{itemize}

Установить Dive на MacOS X можно с помощью \texttt{brew}
\begin{lstlisting}[
style = bash,
numbers = none	
]
brew install dive
\end{lstlisting}



% Источники в "Газовой промышленности" нумеруются по мере упоминания 
\begin{thebibliography}{99}\addcontentsline{toc}{section}{Список литературы}
	\bibitem{mouat:docker-2017}{ \emph{Моуэт Э.} Использование Docker. -- М.: ДМК Пресс, 2017. -- 354 с. }
	
	\bibitem{robbins:bash-2017}{ \emph{Роббинс А.} Bash. Карманный справочник системного администратора, 2-е изд.: Пер. с англ. -- СПб.: ООО <<Альфа-книга>>, 2017. -- 152 с.}
	
	\bibitem{olifer:compnets-2020}{\emph{Олифер В.}, \emph{Олифер Н.} Компьютерные сети. Принципы, технологии, протоколы. -- СПб.: Питер, 2020. -- 1008 с.}
\end{thebibliography}

%\listoffigures\addcontentsline{toc}{section}{Список иллюстраций}


\end{document}
